---
title: "MORS Emerging Techniques Tidymodels"
author: "MAJ Dusty Turner  |  Max Kuhn"
date: "4 December 2019"
output: 
  powerpoint_presentation:
    slide_level: 2
    reference_doc: template.pptx
  fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE, warning=FALSE)
options(scipen = 999)
library(knitr)
library(jpeg)
library(flextable)
library(lubridate)
```

## Slide to Delete

```{r echo=FALSE, message=FALSE, warning=FALSE,out.width=100, fig.cap="Follow Along!"}
include_graphics("03_presentation_files/qrcode.png")
```

## Who am I?

Army 

- Combat Engineer
- Platoon Leader / XO / Company Commander
- Geospatial / Sapper / Route Clearance
- Hawaii / White Sands Missile Range / Iraq / Afghanistan

Education

- West Point '07
  - Operations Research, BS
- Missouri University of Science and Technology '12
  - Engineering Management, MS
- THE Ohio State '16
  - Integrated Systems Engineering, MS
  - Applied Statistics, Graduate Minor

Data Science

- R User Since '14
- Catch me on Twitter [`@dtdusty`](www.twitter.com/dtdusty)
- <http://dusty-turner.netlify.com/>


## What am I assuming about you?

:::::::::::::: {.columns}
::: {.column}

- Data Science Background

- Moderate R Background

- Pretty much a 'super nerd'

:::
::: {.column}

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap="www.tenor.com"}
include_graphics("03_presentation_files/nerd.gif")
```

:::
::::::::::::::

## What are we going to talk about?

:::::::::::::: {.columns}
::: {.column}
Lets talk about

- ...modeling in R the old way (`caret`)

- ...modeling in R the (very) new way (`tidymodels`)

- ...an example (Flying Hour Challlenge)

:::
::: {.column}

```{r echo=FALSE, message=FALSE, warning=FALSE}
include_graphics("03_presentation_files/tidymodelshex.png")
```

:::
::::::::::::::

## Background: Out with "The Old"

The `Caret` Package

- Classification And REgression Training

Functionality

- Inpute Missing Data
- Split Test/Train/Validate Set
- Supports a Multitude of Modeling Techniques
- Supports Cross Validation

Drawbacks

- Requires unique syntax to support each package / imputation technique
- Not 'tidy' compatible

## Background: In with "The New"

The `tidymodels` package

- Released in October 2019

Functionality

- Inpute Missing Data 
- Split Test/Train/Validate Set
- Supports a Multitude of Modeling Techniques
- Supports Cross Validation
- Supports model performance measurements

Advantages

- Streamlines syntax for all model types / packages
- 'tidy' compatible
- Easy to compare model performance

## More details of `tidymodels`

From the documentation:

- "`tidymodels` is a ''meta-package" for modeling and statistical analysis that share the underlying design philosophy, grammar, and data structures of the `tidyverse`."

- Imports the following packages:

  - `broom`: takes messy output and makes them 'tidy' compatible
  - `infer`: modern approach to statistical inference 
  - `recipes`: general data processor with a modern interface that incorporate feature engineering, imputation, and other help tools
  - `yardstick`: contains tools for evaluating models (e.g. accuracy, RMSE, etc.)
  - `tidypredict`: translates some model prediction equations to SQL for high-performance computing
  - `tidyposterior`: used to compare models using resampling and Bayesian analysis
  - `tidytext`: contains tidy tools for quantitative text analysis

<https://github.com/tidymodels/tidymodels>

`install.packages("tidymodels")`

## More details of `tidymodels`

:::::::::::::: {.columns}
::: {.column}

Author is Max Kuhn of RStudio [`@topepo`](www.twitter.com/topepo)

Kuhn, M., & Johnson, K. (2013). Applied predictive modeling. New York: Springer.

:::
::: {.column}

```{r echo=FALSE, message=FALSE, warning=FALSE,out.width=100, fig.subcap="Max Kuhn at West Point Fall 2018"}
include_graphics("03_presentation_files/max.JPG")
```

:::
::::::::::::::

# Where Does This Fit In The Modeling Process?

## Tidyverse Schema

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap="https://www.tidyverse.org/"}
include_graphics("03_presentation_files/tidyverse.png")
```

## Tidymodels Schema

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap="https://www.tidyverse.org/"}
include_graphics("03_presentation_files/tidymodels.png")
```

## What We're Going to Do:

- Introduce a Data Problem

  - Flying Hour Challenge

- Show the 'old techniques'

  - `caret`

- Show the new technique

  - `tidymodels`

- Discuss Challenges


## Libraries

```{r}
library(tidyverse)
library(tidymodels)
library(caret)
```

## Flying Hour Challenge - Inspect the Data

```{r include=FALSE}
rawdata = read_csv("01_data/mors_cleaned_ID_simplify.csv") %>%
  janitor::clean_names()
```

```{r, fig.align='left', fig.width=8}
read_csv("01_data/mors_cleaned_ID_simplify.csv") %>%
  janitor::clean_names() %>% 
  select(hours_flown, as_of_date,mc_percent,poss_hrs,fmc_percent,age_years_by_accept_date) %>%
  head(10) %>%  flextable() %>%  autofit()
```


## `Skimr` Numeric Variables

```{r echo=FALSE}
helper =
skimr::skim(rawdata) %>%
  filter(type=="numeric") %>%
  select(-type)  %>%
  filter(stat == "hist") %>%
  select(variable, formatted)

skimr::skim(rawdata)  %>%
  filter(type=="numeric") %>%
  select(-type)  %>%
  pivot_wider(id_cols = variable, names_from = stat) %>%
  select(-hist) %>%
  left_join(helper, by = "variable") %>%
  rename(hist = formatted) %>%
  select(-c(complete,p25,p75)) %>%
  mutate_if(is.numeric, round, 2) %>%
  slice(1:15) %>%
  flextable() %>% autofit()
```

## `Skimr` Character and Date Variables

### Character Variables

```{r echo=FALSE}
skimr::skim(rawdata)  %>%
  filter(type=="character") %>%
  select(-type)  %>%
  pivot_wider(id_cols = variable, names_from = stat) %>%
  flextable() %>% autofit()
```

### Date Variables

```{r}
skimr::skim(rawdata)  %>%
  filter(type=="Date") %>%
  select(-type)  %>%
  pivot_wider(id_cols = variable, names_from = stat) %>%
  flextable() %>% autofit()
```

## Flying Hour Challenge - Data Processing

- ensure correct data type

```{r}
rawdata = read_csv("01_data/mors_cleaned_ID_simplify.csv") %>%
  janitor::clean_names() %>% 
  mutate(as_of_date = lubridate::mdy(as_of_date)) 
```

- remove near zero variance 

```{r include=TRUE, eval=FALSE}
nearZeroVar()
```

- linear dependencies 

```{r include=TRUE, eval=FALSE}
findLinearCombos()
```

- handle `NA`s (next slide)

## Handle `NA`s

```{r echo=FALSE}
rawdata %>%
  mutate(row_id = row_number()) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = -row_id) %>%
  mutate(isna = is.na(value)) %>%
  count(name,isna) %>%
  mutate(isna = if_else(isna,"Missing","NotMissing")) %>%
  pivot_wider(names_from = isna, values_from = n) %>%
  arrange(-Missing) %>% 
  head(12) %>% flextable() %>% autofit()
```

## Plot View

```{r echo=FALSE, cache=TRUE, dpi=500}
rawdata %>%
  mutate(row_id = row_number()) %>%
  # select(fy:cab,row_id) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = -row_id) %>%
  mutate(isna = is.na(value)) %>%
  count(name,isna) %>%
  mutate(isna = if_else(isna,"Missing","NotMissing")) %>%
  pivot_wider(names_from = isna, values_from = n) %>%
  filter(!is.na(Missing)) -> helper

library(wesanderson)
pal = wes_palette(name = "GrandBudapest2", n = 2)

rawdata %>%
  select(helper$name) %>%
  mutate(row_id = row_number()) %>%
  # select(fy:cab,row_id) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = -row_id) %>% slice(1:100000) %>%
  mutate(isna = is.na(value))  %>%
  mutate(row_id = as.numeric(row_id)) %>%
  mutate(name = str_sub(name,1,7)) %>%
  ggplot(aes(x = name,y = row_id, fill = isna)) +
    geom_raster(alpha=1) +
    scale_fill_manual(name = "",
        values = pal[2:1],
        # values = c('steelblue', 'tomato3'),
        labels = c("Present", "Missing")) +
    scale_y_continuous(breaks = seq(0,100000,1000)) +
    labs(x = "Variable",
           y = "Row Number", title = "Sample of Missing Values in Rows") +
    coord_flip() +
  theme(legend.position = "bottom")
```

# Caret: Classification And REgression Training

```{r echo=FALSE}
include_graphics("03_presentation_files/caret.png")
```

## `Caret`: Preprocess

```{r}
preprocessvalues = preProcess(rawdata[,-33], method = c("medianImpute","nzv", "center", "scale"))
```

```{r}
caretimpute = predict(preprocessvalues, rawdata)
```

## `Caret`: Split in Train/Testing

```{r}
trainIndex = createDataPartition(caretimpute$hours_flown, p = .7)
dataTrain = caretimpute[trainIndex$Resample1,]
dataTest = caretimpute[-trainIndex$Resample1,]
```

## `Caret`: Build Models 

```{r}
caretlm = train(hours_flown ~ ., data = dataTrain,
                 method = "lm",
                 trControl = trainControl(method = "none"))

caretrf = train(hours_flown ~ ., data = sample_n(dataTrain,5000),
                 method = "rf",
                 trControl = trainControl(method = "none"))

# caretranger = train(hours_flown ~ ., data = sample_n(dataTrain,5000),
#                  method = "ranger",
#                  trControl = trainControl(method = "none"))

caretglm = train(hours_flown ~ ., data = dataTrain,
                 method = "glmnet",
                 trControl = trainControl(method = "none"))
```

## `Caret`: Predict and Evaluate

Predict

```{r}
lm.pred = predict(caretlm, dataTest)
rf.pred = predict(caretrf, dataTest)
glm.pred = predict(caretglm, dataTest)
```

Evaluate Models

```{r include=FALSE}
LM = postResample(pred = lm.pred, dataTest$hours_flown)
RF = postResample(pred = rf.pred, dataTest$hours_flown)
GLM = postResample(pred = glm.pred, dataTest$hours_flown)
```

```{r echo=FALSE}
data.frame(LM = LM,RF = RF,GLM = GLM) %>%
  mutate(model = rownames(.)) %>% 
  pivot_longer(cols = LM:GLM) %>% 
  pivot_wider(names_from = model, values_from = value) %>%
  rename(Model = name) %>%
  arrange(-RMSE) %>%  flextable() %>% autofit()
```

# Tidymodels

```{r echo=FALSE}
include_graphics("03_presentation_files/tidyhex.png")
```


## `Tidymodels`: Split

```{r}
data_split = rawdata %>% initial_split(prop = .7)

data_split 
```

## `Tidymodels`: Preprocess

```{r}
flight_recipe =
data_split %>%
  training() %>%
  recipe(hours_flown ~ .) %>%
  recipes::step_meanimpute(
    age_years_by_accept_date, fmc_percent,nmcs_percent, mc_percent,
    nmcm_percent,nmcm_spt_percent, nmcm_depot_percent,pmcs_percent,pmc_percent,
    pmcm_percent
    ) %>%
  step_corr(
    age_years_by_accept_date, fmc_percent,nmcs_percent,mc_percent,
    nmcm_percent,nmcm_spt_percent, nmcm_depot_percent,pmcs_percent,pmc_percent,
    pmcm_percent
    ) %>%
  step_center(
    age_years_by_accept_date, fmc_percent,nmcs_percent,
    nmcm_percent,nmcm_spt_percent, nmcm_depot_percent,pmcs_percent,pmc_percent,
    pmcm_percent
    ) %>%
  step_scale(
    age_years_by_accept_date, fmc_percent,nmcs_percent,
    nmcm_percent,nmcm_spt_percent, nmcm_depot_percent,pmcs_percent,
    pmcm_percent
  ) %>%
  prep()
```

## `Tidymodels`: Preprocess

```{r}
flight_recipe
```

## `Tidymodels`: Prepare Training and Testing Data

`Juice` Training Data

```{r}
flight_training = juice(flight_recipe)
```

`Bake` Testing Data
 
```{r}
flight_testing = flight_recipe %>%
  bake(testing(data_split))
```

## `Tidymodels`: Build Models

```{r}
flight_lm =
  linear_reg(mode = "regression") %>%
  set_engine("lm") %>%
  fit(hours_flown ~ ., data = flight_training)

flight_rf =
  rand_forest(trees = 10, mode = "regression") %>%
  set_engine("randomForest") %>%
  fit(hours_flown ~ ., data = flight_training)

flight_ranger =
  rand_forest(trees = 50, mode = "regression") %>%
  set_engine("ranger") %>%
  fit(hours_flown ~ ., data = flight_training)

flight_glm =
  linear_reg(mode = "regression") %>%
  set_engine("glmnet") %>%
  fit(hours_flown ~ ., data = flight_training)
```

## `Tidymodels`: Side Note

Models Currently Available

- `lm`
- `tree-based`
- `survival analysis`
- `bayesian`

## `Tidymodels`: Predictions and Evaluate

```{r}
flight_testing %>%
  select(hours_flown) %>%
  bind_cols(
    predict(flight_lm, flight_testing) %>% rename(lm_pred = .pred),
    predict(flight_rf, flight_testing) %>% rename(rf_pred = .pred),
    predict(flight_ranger, flight_testing) %>% rename(ranger_pred = .pred),
    predict(flight_glm, flight_testing, penalty = 10) %>% rename(lasso_glm = .pred),
  ) %>%
  pivot_longer(cols = -hours_flown) %>%
  rename(model = name, prediction = value) %>%
  group_by(model) %>%
  metrics(truth = hours_flown, estimate = prediction) %>%
  select(-.estimator) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  arrange(rmse)
```

## Tidymodels: The Next Fronteir 

Further incorporation of model metrics (cross validation).

```{r}
cross_data = vfold_cv(flight_training, v = 10)
cross_data
```

Not quite there yet

## In Summary

`caret`

- 65,800 hits on Google Scholar
- Proven to be successful
- Clunky syntax

`tidymodels`

- 122 hits on Google Scholar
- Streamlined 'tidy' syntax
- Still in development
- Backing of R Studio

## Thanks!

:::::::::::::: {.columns}
::: {.column}

### MAJ Dusty Turner

Twitter: [`@dtdusty`](www.twitter.com/dtdusty)

Eamil: <dusty.s.turner.mil@mail.mil>

Github [dusty-turner](https://github.com/dusty-turner)

Personal Website [https://dusty-turner.netlify.com/](https://dusty-turner.netlify.com/)

:::
::: {.column}

### Max Kuhn

Twitter [`@topepo`](www.twitter.com/topepo)

Github [topepo](https://github.com/topepo)

:::
::::::::::::::

## QR Dusty Contact

```{r echo=FALSE}
include_graphics("03_presentation_files/qrcodecontact.png")
```

## QR Presentation

```{r echo=FALSE}
include_graphics("03_presentation_files/qrcode.png")
```

